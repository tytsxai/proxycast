# LLM Flow Monitor - è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ

> å‚è€ƒ mitmproxy çš„ Flow æ¨¡å‹ï¼Œä¸º ProxyCast è®¾è®¡ä¸€å¥—å®Œæ•´çš„ LLM API æµé‡ç›‘æ§ç³»ç»Ÿï¼Œ
> ç”¨äºæ•è·ã€å­˜å‚¨ã€åˆ†æå’Œå›æ”¾ AI Agent ä¸å¤§æ¨¡å‹ä¹‹é—´çš„å®Œæ•´äº¤äº’æ•°æ®ã€‚

## ä¸€ã€èƒŒæ™¯ä¸ç›®æ ‡

### 1.1 å½“å‰é—®é¢˜

1. **æ—¥å¿—ä¿¡æ¯ä¸å®Œæ•´**ï¼šå½“å‰ `RequestLog` åªè®°å½•å…ƒæ•°æ®ï¼ˆidã€providerã€modelã€durationã€tokensï¼‰ï¼Œä¸ä¿å­˜å®Œæ•´çš„è¯·æ±‚å’Œå“åº”å†…å®¹
2. **æµå¼å“åº”ä¸¢å¤±**ï¼šSSE æµå¼å“åº”çš„ chunks åˆ†æ•£ï¼Œæ— æ³•é‡å»ºå®Œæ•´çš„å“åº”å†…å®¹
3. **æ— æ³•è°ƒè¯• Agent**ï¼šå¼€å‘ AI Agent æ—¶ï¼Œéœ€è¦æŸ¥çœ‹å®Œæ•´çš„ prompt å’Œ response æ¥è°ƒä¼˜
4. **ç¼ºä¹å†å²å›æ”¾**ï¼šæ— æ³•å›æ”¾å†å²è¯·æ±‚ï¼Œéš¾ä»¥å¤ç°é—®é¢˜
5. **æ•°æ®ä¸å¯å¯¼å‡º**ï¼šæ— æ³•å¯¼å‡ºä¸ºæ ‡å‡†æ ¼å¼ï¼ˆå¦‚ HARï¼‰ä¾›å…¶ä»–å·¥å…·åˆ†æ

### 1.2 è®¾è®¡ç›®æ ‡

1. **å®Œæ•´æ•è·**ï¼šè®°å½•æ¯ä¸ªè¯·æ±‚çš„å®Œæ•´ headersã€bodyã€å“åº”å†…å®¹
2. **æµå¼é‡å»º**ï¼šè‡ªåŠ¨å°† SSE chunks åˆå¹¶ä¸ºå®Œæ•´å“åº”
3. **é«˜æ•ˆå­˜å‚¨**ï¼šå†…å­˜ + æ–‡ä»¶åŒå±‚å­˜å‚¨ï¼Œæ”¯æŒå¤§é‡è¯·æ±‚
4. **çµæ´»æŸ¥è¯¢**ï¼šæŒ‰æ—¶é—´ã€æ¨¡å‹ã€providerã€å†…å®¹ç­‰å¤šç»´åº¦è¿‡æ»¤
5. **æ ‡å‡†å¯¼å‡º**ï¼šæ”¯æŒ HARã€JSONã€Markdown ç­‰æ ¼å¼å¯¼å‡º
6. **å®æ—¶ç›‘æ§**ï¼šå‰ç«¯å®æ—¶å±•ç¤ºè¯·æ±‚åˆ—è¡¨å’Œè¯¦æƒ…
7. **éšç§ä¿æŠ¤**ï¼šæ•æ„Ÿä¿¡æ¯è„±æ•ï¼Œå¯é…ç½®å­˜å‚¨ç­–ç•¥

---

## äºŒã€æ•°æ®æ¨¡å‹è®¾è®¡

### 2.1 æ ¸å¿ƒæ•°æ®ç»“æ„

```rust
/// LLM è¯·æ±‚/å“åº”æµ
/// ç±»ä¼¼ mitmproxy çš„ HTTPFlowï¼Œä½†ä¸“é—¨é’ˆå¯¹ LLM API ä¼˜åŒ–
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMFlow {
    /// å”¯ä¸€æ ‡è¯†ç¬¦
    pub id: String,
    
    /// æµç±»å‹
    pub flow_type: FlowType,
    
    /// è¯·æ±‚ä¿¡æ¯
    pub request: LLMRequest,
    
    /// å“åº”ä¿¡æ¯ï¼ˆå¯èƒ½ä¸ºç©ºï¼Œå¦‚è¯·æ±‚å¤±è´¥ï¼‰
    pub response: Option<LLMResponse>,
    
    /// é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå‘ç”Ÿé”™è¯¯ï¼‰
    pub error: Option<FlowError>,
    
    /// å…ƒæ•°æ®
    pub metadata: FlowMetadata,
    
    /// æ—¶é—´æˆ³
    pub timestamps: FlowTimestamps,
    
    /// æµçŠ¶æ€
    pub state: FlowState,
    
    /// ç”¨æˆ·æ ‡è®°å’Œæ³¨é‡Š
    pub annotations: FlowAnnotations,
}

/// æµç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FlowType {
    /// OpenAI Chat Completions
    ChatCompletions,
    /// Anthropic Messages
    AnthropicMessages,
    /// Gemini Generate Content
    GeminiGenerateContent,
    /// Embeddings
    Embeddings,
    /// å…¶ä»–
    Other(String),
}

/// æµçŠ¶æ€
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FlowState {
    /// ç­‰å¾…å“åº”
    Pending,
    /// æ­£åœ¨æµå¼ä¼ è¾“
    Streaming,
    /// å·²å®Œæˆ
    Completed,
    /// å¤±è´¥
    Failed,
    /// å·²å–æ¶ˆ
    Cancelled,
    /// å·²æ‹¦æˆªï¼ˆç”¨äºè°ƒè¯•ï¼‰
    Intercepted,
}
```

### 2.2 è¯·æ±‚æ•°æ®ç»“æ„

```rust
/// LLM è¯·æ±‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMRequest {
    /// HTTP æ–¹æ³•
    pub method: String,
    
    /// è¯·æ±‚è·¯å¾„
    pub path: String,
    
    /// è¯·æ±‚å¤´
    pub headers: HashMap<String, String>,
    
    /// åŸå§‹è¯·æ±‚ä½“ï¼ˆJSONï¼‰
    pub body: serde_json::Value,
    
    /// è§£æåçš„æ¶ˆæ¯åˆ—è¡¨
    pub messages: Vec<Message>,
    
    /// ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰
    pub system_prompt: Option<String>,
    
    /// å·¥å…·å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
    pub tools: Option<Vec<ToolDefinition>>,
    
    /// è¯·æ±‚çš„æ¨¡å‹åç§°
    pub model: String,
    
    /// åŸå§‹æ¨¡å‹åç§°ï¼ˆåˆ«åè§£æå‰ï¼‰
    pub original_model: Option<String>,
    
    /// è¯·æ±‚å‚æ•°
    pub parameters: RequestParameters,
    
    /// è¯·æ±‚ä½“å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    pub size_bytes: usize,
    
    /// è¯·æ±‚å¼€å§‹æ—¶é—´æˆ³
    pub timestamp: DateTime<Utc>,
}

/// æ¶ˆæ¯ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Message {
    /// è§’è‰²
    pub role: MessageRole,
    
    /// å†…å®¹ï¼ˆå¯ä»¥æ˜¯æ–‡æœ¬æˆ–å¤šæ¨¡æ€ï¼‰
    pub content: MessageContent,
    
    /// å·¥å…·è°ƒç”¨ï¼ˆassistant æ¶ˆæ¯ï¼‰
    pub tool_calls: Option<Vec<ToolCall>>,
    
    /// å·¥å…·ç»“æœï¼ˆtool æ¶ˆæ¯ï¼‰
    pub tool_result: Option<ToolResult>,
    
    /// æ¶ˆæ¯åç§°ï¼ˆfunction/tool æ¶ˆæ¯ï¼‰
    pub name: Option<String>,
}

/// æ¶ˆæ¯è§’è‰²
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MessageRole {
    System,
    User,
    Assistant,
    Tool,
    Function,
}

/// æ¶ˆæ¯å†…å®¹ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum MessageContent {
    /// çº¯æ–‡æœ¬
    Text(String),
    
    /// å¤šæ¨¡æ€å†…å®¹
    MultiModal(Vec<ContentPart>),
}

/// å†…å®¹éƒ¨åˆ†
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum ContentPart {
    /// æ–‡æœ¬
    #[serde(rename = "text")]
    Text { text: String },
    
    /// å›¾ç‰‡
    #[serde(rename = "image_url")]
    Image { 
        image_url: ImageUrl,
        /// å›¾ç‰‡æ‘˜è¦ï¼ˆç”¨äºæ˜¾ç¤ºï¼Œä¸å­˜å‚¨å®Œæ•´ base64ï¼‰
        #[serde(skip_serializing_if = "Option::is_none")]
        thumbnail: Option<String>,
    },
    
    /// éŸ³é¢‘
    #[serde(rename = "audio")]
    Audio { 
        audio: AudioData,
    },
    
    /// æ–‡ä»¶
    #[serde(rename = "file")]
    File {
        file: FileData,
    },
}

/// è¯·æ±‚å‚æ•°
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct RequestParameters {
    /// æ¸©åº¦
    pub temperature: Option<f32>,
    /// Top P
    pub top_p: Option<f32>,
    /// æœ€å¤§ tokens
    pub max_tokens: Option<u32>,
    /// åœæ­¢åºåˆ—
    pub stop: Option<Vec<String>>,
    /// æ˜¯å¦æµå¼
    pub stream: bool,
    /// å…¶ä»–å‚æ•°
    #[serde(flatten)]
    pub extra: HashMap<String, serde_json::Value>,
}
```

### 2.3 å“åº”æ•°æ®ç»“æ„

```rust
/// LLM å“åº”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMResponse {
    /// HTTP çŠ¶æ€ç 
    pub status_code: u16,
    
    /// çŠ¶æ€æ–‡æœ¬
    pub status_text: String,
    
    /// å“åº”å¤´
    pub headers: HashMap<String, String>,
    
    /// åŸå§‹å“åº”ä½“ï¼ˆå®Œæ•´ JSONï¼Œæµå¼å“åº”ä¼šè¢«é‡å»ºï¼‰
    pub body: serde_json::Value,
    
    /// æå–çš„æ–‡æœ¬å†…å®¹
    pub content: String,
    
    /// æ€ç»´é“¾å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
    pub thinking: Option<ThinkingContent>,
    
    /// å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
    pub tool_calls: Vec<ToolCall>,
    
    /// Token ä½¿ç”¨ç»Ÿè®¡
    pub usage: TokenUsage,
    
    /// åœæ­¢åŸå› 
    pub stop_reason: Option<StopReason>,
    
    /// å“åº”ä½“å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    pub size_bytes: usize,
    
    /// å“åº”å¼€å§‹æ—¶é—´æˆ³
    pub timestamp_start: DateTime<Utc>,
    
    /// å“åº”ç»“æŸæ—¶é—´æˆ³
    pub timestamp_end: DateTime<Utc>,
    
    /// æµå¼å“åº”ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯æµå¼ï¼‰
    pub stream_info: Option<StreamInfo>,
}

/// æ€ç»´é“¾å†…å®¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ThinkingContent {
    /// æ€ç»´é“¾æ–‡æœ¬
    pub text: String,
    /// æ€ç»´é“¾ token æ•°
    pub tokens: Option<u32>,
    /// æ€ç»´é“¾ç­¾åï¼ˆç”¨äºéªŒè¯ï¼‰
    pub signature: Option<String>,
}

/// å·¥å…·è°ƒç”¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCall {
    /// è°ƒç”¨ ID
    pub id: String,
    /// å·¥å…·ç±»å‹
    pub call_type: String,
    /// å‡½æ•°ä¿¡æ¯
    pub function: FunctionCall,
}

/// å‡½æ•°è°ƒç”¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionCall {
    /// å‡½æ•°å
    pub name: String,
    /// å‚æ•°ï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
    pub arguments: String,
    /// è§£æåçš„å‚æ•°ï¼ˆæ–¹ä¾¿æŸ¥çœ‹ï¼‰
    pub parsed_arguments: Option<serde_json::Value>,
}

/// Token ä½¿ç”¨ç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct TokenUsage {
    /// è¾“å…¥ tokens
    pub input_tokens: u32,
    /// è¾“å‡º tokens
    pub output_tokens: u32,
    /// ç¼“å­˜è¯»å– tokens
    pub cache_read_tokens: Option<u32>,
    /// ç¼“å­˜å†™å…¥ tokens
    pub cache_write_tokens: Option<u32>,
    /// æ€ç»´é“¾ tokens
    pub thinking_tokens: Option<u32>,
    /// æ€» tokens
    pub total_tokens: u32,
}

/// åœæ­¢åŸå› 
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StopReason {
    /// æ­£å¸¸ç»“æŸ
    Stop,
    /// è¾¾åˆ°é•¿åº¦é™åˆ¶
    Length,
    /// å·¥å…·è°ƒç”¨
    ToolUse,
    /// å†…å®¹è¿‡æ»¤
    ContentFilter,
    /// å…¶ä»–
    Other(String),
}

/// æµå¼å“åº”ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StreamInfo {
    /// æ€» chunk æ•°
    pub chunk_count: u32,
    /// ç¬¬ä¸€ä¸ª chunk å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    pub first_chunk_latency_ms: u64,
    /// å¹³å‡ chunk é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    pub avg_chunk_interval_ms: f64,
    /// åŸå§‹ chunksï¼ˆå¯é€‰ä¿å­˜ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub raw_chunks: Option<Vec<StreamChunk>>,
}

/// æµå¼ chunk
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StreamChunk {
    /// åºå·
    pub index: u32,
    /// æ—¶é—´æˆ³
    pub timestamp: DateTime<Utc>,
    /// åŸå§‹æ•°æ®
    pub data: String,
    /// å¢é‡å†…å®¹
    pub delta_content: Option<String>,
}
```

### 2.4 å…ƒæ•°æ®ç»“æ„

```rust
/// æµå…ƒæ•°æ®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowMetadata {
    /// Provider ç±»å‹
    pub provider: ProviderType,
    
    /// ä½¿ç”¨çš„å‡­è¯ ID
    pub credential_id: Option<String>,
    
    /// å‡­è¯åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    pub credential_name: Option<String>,
    
    /// é‡è¯•æ¬¡æ•°
    pub retry_count: u32,
    
    /// å®¢æˆ·ç«¯ä¿¡æ¯
    pub client_info: ClientInfo,
    
    /// è·¯ç”±ä¿¡æ¯
    pub routing_info: RoutingInfo,
    
    /// æ³¨å…¥çš„å‚æ•°
    pub injected_params: Option<HashMap<String, serde_json::Value>>,
    
    /// ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    pub context_usage_percentage: Option<f32>,
}

/// å®¢æˆ·ç«¯ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClientInfo {
    /// å®¢æˆ·ç«¯ IP
    pub ip: Option<String>,
    /// User-Agent
    pub user_agent: Option<String>,
    /// å®¢æˆ·ç«¯ SDK
    pub sdk: Option<String>,
    /// å®¢æˆ·ç«¯ç‰ˆæœ¬
    pub sdk_version: Option<String>,
}

/// è·¯ç”±ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RoutingInfo {
    /// åŸå§‹æ¨¡å‹ï¼ˆåˆ«åï¼‰
    pub original_model: String,
    /// è§£æåçš„æ¨¡å‹
    pub resolved_model: String,
    /// è·¯ç”±åˆ°çš„ Provider
    pub routed_provider: ProviderType,
    /// åŒ¹é…çš„è·¯ç”±è§„åˆ™
    pub matched_rule: Option<String>,
}

/// æ—¶é—´æˆ³é›†åˆ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowTimestamps {
    /// è¯·æ±‚åˆ›å»ºæ—¶é—´
    pub created: DateTime<Utc>,
    /// è¯·æ±‚å‘é€æ—¶é—´
    pub request_start: DateTime<Utc>,
    /// è¯·æ±‚å‘é€å®Œæˆæ—¶é—´
    pub request_end: Option<DateTime<Utc>>,
    /// å“åº”å¼€å§‹æ—¶é—´ï¼ˆæ”¶åˆ°ç¬¬ä¸€ä¸ªå­—èŠ‚ï¼‰
    pub response_start: Option<DateTime<Utc>>,
    /// å“åº”ç»“æŸæ—¶é—´
    pub response_end: Option<DateTime<Utc>>,
    /// æ€»è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    pub duration_ms: u64,
    /// TTFBï¼ˆTime To First Byteï¼Œæ¯«ç§’ï¼‰
    pub ttfb_ms: Option<u64>,
}

/// ç”¨æˆ·æ ‡æ³¨
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct FlowAnnotations {
    /// ç”¨æˆ·æ ‡è®°ï¼ˆå¦‚ â­ã€ğŸ”´ã€ğŸŸ¢ï¼‰
    pub marker: Option<String>,
    /// ç”¨æˆ·å¤‡æ³¨
    pub comment: Option<String>,
    /// æ ‡ç­¾
    pub tags: Vec<String>,
    /// æ˜¯å¦å·²æ”¶è—
    pub starred: bool,
}
```

### 2.5 é”™è¯¯ç»“æ„

```rust
/// æµé”™è¯¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowError {
    /// é”™è¯¯ç±»å‹
    pub error_type: FlowErrorType,
    /// é”™è¯¯æ¶ˆæ¯
    pub message: String,
    /// HTTP çŠ¶æ€ç ï¼ˆå¦‚æœæœ‰ï¼‰
    pub status_code: Option<u16>,
    /// åŸå§‹é”™è¯¯å“åº”
    pub raw_response: Option<String>,
    /// é”™è¯¯å‘ç”Ÿæ—¶é—´
    pub timestamp: DateTime<Utc>,
    /// æ˜¯å¦å¯é‡è¯•
    pub retryable: bool,
}

/// é”™è¯¯ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FlowErrorType {
    /// ç½‘ç»œé”™è¯¯
    Network,
    /// è¶…æ—¶
    Timeout,
    /// è®¤è¯å¤±è´¥
    Authentication,
    /// é™æµ
    RateLimit,
    /// å†…å®¹è¿‡æ»¤
    ContentFilter,
    /// æœåŠ¡ç«¯é”™è¯¯
    ServerError,
    /// è¯·æ±‚æ ¼å¼é”™è¯¯
    BadRequest,
    /// æ¨¡å‹ä¸å¯ç”¨
    ModelUnavailable,
    /// Token è¶…é™
    TokenLimitExceeded,
    /// å…¶ä»–
    Other,
}
```

---

## ä¸‰ã€æµå¼å“åº”é‡å»º

### 3.1 SSE è§£æå™¨

```rust
/// SSE æµé‡å»ºå™¨
pub struct StreamRebuilder {
    /// ç´¯ç§¯çš„ chunks
    chunks: Vec<StreamChunk>,
    /// ç´¯ç§¯çš„å†…å®¹
    content_buffer: String,
    /// ç´¯ç§¯çš„ tool calls
    tool_calls_buffer: HashMap<String, ToolCallBuilder>,
    /// ç´¯ç§¯çš„ thinking
    thinking_buffer: Option<String>,
    /// ç¬¬ä¸€ä¸ª chunk æ—¶é—´
    first_chunk_time: Option<DateTime<Utc>>,
    /// ä¸Šä¸€ä¸ª chunk æ—¶é—´
    last_chunk_time: Option<DateTime<Utc>>,
    /// æµæ ¼å¼
    format: StreamFormat,
}

/// æµæ ¼å¼
pub enum StreamFormat {
    /// OpenAI æ ¼å¼
    OpenAI,
    /// Anthropic æ ¼å¼
    Anthropic,
    /// Gemini æ ¼å¼
    Gemini,
    /// æœªçŸ¥æ ¼å¼
    Unknown,
}

impl StreamRebuilder {
    /// å¤„ç†ä¸€ä¸ª SSE äº‹ä»¶
    pub fn process_event(&mut self, event: &str, data: &str) -> Result<(), Error> {
        let chunk = StreamChunk {
            index: self.chunks.len() as u32,
            timestamp: Utc::now(),
            data: data.to_string(),
            delta_content: None,
        };
        
        // æ ¹æ®æ ¼å¼è§£æå¢é‡å†…å®¹
        match self.format {
            StreamFormat::OpenAI => self.process_openai_chunk(data, &mut chunk)?,
            StreamFormat::Anthropic => self.process_anthropic_chunk(event, data, &mut chunk)?,
            StreamFormat::Gemini => self.process_gemini_chunk(data, &mut chunk)?,
            _ => {},
        }
        
        self.chunks.push(chunk);
        Ok(())
    }
    
    /// å®Œæˆé‡å»ºï¼Œè¿”å›å®Œæ•´å“åº”
    pub fn finish(self) -> LLMResponse {
        // æ„å»ºå®Œæ•´çš„å“åº”å¯¹è±¡
        LLMResponse {
            content: self.content_buffer,
            tool_calls: self.tool_calls_buffer.into_values().map(|b| b.build()).collect(),
            thinking: self.thinking_buffer.map(|t| ThinkingContent { text: t, tokens: None, signature: None }),
            stream_info: Some(StreamInfo {
                chunk_count: self.chunks.len() as u32,
                first_chunk_latency_ms: self.calculate_first_chunk_latency(),
                avg_chunk_interval_ms: self.calculate_avg_interval(),
                raw_chunks: if self.should_save_raw_chunks() { Some(self.chunks) } else { None },
            }),
            // ... å…¶ä»–å­—æ®µ
        }
    }
}
```

### 3.2 ä¸åŒæ ¼å¼å¤„ç†

```rust
impl StreamRebuilder {
    /// å¤„ç† OpenAI æ ¼å¼çš„ chunk
    fn process_openai_chunk(&mut self, data: &str, chunk: &mut StreamChunk) -> Result<(), Error> {
        if data == "[DONE]" {
            return Ok(());
        }
        
        let parsed: OpenAIStreamChunk = serde_json::from_str(data)?;
        
        for choice in &parsed.choices {
            if let Some(delta) = &choice.delta {
                // æ–‡æœ¬å†…å®¹
                if let Some(content) = &delta.content {
                    self.content_buffer.push_str(content);
                    chunk.delta_content = Some(content.clone());
                }
                
                // å·¥å…·è°ƒç”¨
                if let Some(tool_calls) = &delta.tool_calls {
                    for tc in tool_calls {
                        self.process_tool_call_delta(tc);
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// å¤„ç† Anthropic æ ¼å¼çš„ chunk
    fn process_anthropic_chunk(&mut self, event: &str, data: &str, chunk: &mut StreamChunk) -> Result<(), Error> {
        match event {
            "content_block_delta" => {
                let parsed: AnthropicDelta = serde_json::from_str(data)?;
                match &parsed.delta {
                    Delta::TextDelta { text } => {
                        self.content_buffer.push_str(text);
                        chunk.delta_content = Some(text.clone());
                    },
                    Delta::ThinkingDelta { thinking } => {
                        self.thinking_buffer.get_or_insert(String::new()).push_str(thinking);
                    },
                    Delta::InputJsonDelta { partial_json } => {
                        // å¤„ç†å·¥å…·è°ƒç”¨å‚æ•°
                        self.process_tool_call_json_delta(parsed.index, partial_json);
                    },
                }
            },
            "content_block_start" => {
                // å¤„ç†æ–°çš„å†…å®¹å—
            },
            "message_delta" => {
                // å¤„ç†æ¶ˆæ¯çº§åˆ«çš„æ›´æ–°ï¼ˆstop_reason, usage ç­‰ï¼‰
            },
            _ => {},
        }
        
        Ok(())
    }
}
```

---

## å››ã€å­˜å‚¨ç³»ç»Ÿè®¾è®¡

### 4.1 åŒå±‚å­˜å‚¨æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æŸ¥è¯¢å±‚                           â”‚
â”‚  (æŒ‰ ID / æ—¶é—´ / æ¨¡å‹ / Provider / å†…å®¹ æŸ¥è¯¢)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å†…å­˜ç¼“å­˜   â”‚   â”‚   ç´¢å¼•å±‚    â”‚   â”‚   æ–‡ä»¶å±‚    â”‚
â”‚ (çƒ­æ•°æ®)    â”‚   â”‚  (SQLite)   â”‚   â”‚  (JSONL)    â”‚
â”‚ æœ€è¿‘ 1000   â”‚   â”‚ å…ƒæ•°æ®ç´¢å¼•  â”‚   â”‚ å®Œæ•´æ•°æ®    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 å†…å­˜ç¼“å­˜

```rust
/// å†…å­˜ Flow å­˜å‚¨
pub struct FlowMemoryStore {
    /// æŒ‰ ID ç´¢å¼•çš„ flows
    flows: HashMap<String, Arc<RwLock<LLMFlow>>>,
    /// æŒ‰æ—¶é—´æ’åºçš„ flow IDs
    ordered_ids: VecDeque<String>,
    /// æœ€å¤§ç¼“å­˜æ•°é‡
    max_size: usize,
    /// å†…å­˜ä½¿ç”¨ä¼°ç®—
    memory_usage: AtomicUsize,
}

impl FlowMemoryStore {
    /// æ·»åŠ  flow
    pub fn add(&mut self, flow: LLMFlow) {
        let id = flow.id.clone();
        let size = self.estimate_size(&flow);
        
        self.flows.insert(id.clone(), Arc::new(RwLock::new(flow)));
        self.ordered_ids.push_back(id);
        self.memory_usage.fetch_add(size, Ordering::Relaxed);
        
        // é©±é€æ—§æ•°æ®
        while self.ordered_ids.len() > self.max_size {
            if let Some(old_id) = self.ordered_ids.pop_front() {
                if let Some(old_flow) = self.flows.remove(&old_id) {
                    let old_size = self.estimate_size(&old_flow.read());
                    self.memory_usage.fetch_sub(old_size, Ordering::Relaxed);
                }
            }
        }
    }
    
    /// è·å–æœ€è¿‘ N æ¡
    pub fn get_recent(&self, limit: usize) -> Vec<Arc<RwLock<LLMFlow>>> {
        self.ordered_ids
            .iter()
            .rev()
            .take(limit)
            .filter_map(|id| self.flows.get(id).cloned())
            .collect()
    }
}
```

### 4.3 æ–‡ä»¶æŒä¹…åŒ–

```rust
/// Flow æ–‡ä»¶å­˜å‚¨
pub struct FlowFileStore {
    /// å­˜å‚¨ç›®å½•
    base_dir: PathBuf,
    /// å½“å‰å†™å…¥æ–‡ä»¶
    current_file: RwLock<Option<FlowWriter>>,
    /// è½®è½¬é…ç½®
    rotation_config: RotationConfig,
}

/// è½®è½¬é…ç½®
pub struct RotationConfig {
    /// æŒ‰æ—¥æœŸè½®è½¬
    pub rotate_daily: bool,
    /// å•æ–‡ä»¶æœ€å¤§å¤§å°
    pub max_file_size: u64,
    /// ä¿ç•™å¤©æ•°
    pub retention_days: u32,
    /// æ˜¯å¦å‹ç¼©æ—§æ–‡ä»¶
    pub compress_old: bool,
}

impl FlowFileStore {
    /// å­˜å‚¨æ–‡ä»¶ç»“æ„ï¼š
    /// ~/.proxycast/flows/
    /// â”œâ”€â”€ 2024-01-15/
    /// â”‚   â”œâ”€â”€ flows_001.jsonl
    /// â”‚   â”œâ”€â”€ flows_002.jsonl
    /// â”‚   â””â”€â”€ index.sqlite  (å½“æ—¥ç´¢å¼•)
    /// â”œâ”€â”€ 2024-01-14/
    /// â”‚   â”œâ”€â”€ flows.jsonl.gz  (å‹ç¼©å)
    /// â”‚   â””â”€â”€ index.sqlite
    /// â””â”€â”€ global_index.sqlite  (å…¨å±€ç´¢å¼•)
    
    /// å†™å…¥ flow
    pub async fn write(&self, flow: &LLMFlow) -> Result<(), Error> {
        let mut writer = self.get_or_create_writer().await?;
        
        // å†™å…¥ JSONL
        let json = serde_json::to_string(flow)?;
        writer.write_line(&json).await?;
        
        // æ›´æ–°ç´¢å¼•
        self.update_index(flow).await?;
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦è½®è½¬
        if writer.size() > self.rotation_config.max_file_size {
            self.rotate().await?;
        }
        
        Ok(())
    }
    
    /// æŒ‰æ¡ä»¶æŸ¥è¯¢
    pub async fn query(&self, filter: &FlowFilter) -> Result<Vec<LLMFlow>, Error> {
        // å…ˆæŸ¥è¯¢ç´¢å¼•è·å–æ–‡ä»¶ä½ç½®
        let locations = self.query_index(filter).await?;
        
        // ä»æ–‡ä»¶è¯»å–
        let mut flows = Vec::new();
        for loc in locations {
            let flow = self.read_flow(&loc).await?;
            if filter.matches(&flow) {
                flows.push(flow);
            }
        }
        
        Ok(flows)
    }
}
```

### 4.4 SQLite ç´¢å¼•

```sql
-- å…¨å±€ç´¢å¼•è¡¨
CREATE TABLE flow_index (
    id TEXT PRIMARY KEY,
    created_at DATETIME NOT NULL,
    provider TEXT NOT NULL,
    model TEXT NOT NULL,
    status TEXT NOT NULL,
    duration_ms INTEGER,
    input_tokens INTEGER,
    output_tokens INTEGER,
    has_error BOOLEAN DEFAULT FALSE,
    has_tool_calls BOOLEAN DEFAULT FALSE,
    has_thinking BOOLEAN DEFAULT FALSE,
    file_path TEXT NOT NULL,
    file_offset INTEGER NOT NULL,
    -- ç”¨äºå…¨æ–‡æœç´¢
    content_preview TEXT,
    request_preview TEXT
);

CREATE INDEX idx_created_at ON flow_index(created_at);
CREATE INDEX idx_provider ON flow_index(provider);
CREATE INDEX idx_model ON flow_index(model);
CREATE INDEX idx_status ON flow_index(status);

-- å…¨æ–‡æœç´¢è¡¨ï¼ˆå¯é€‰ï¼Œä½¿ç”¨ FTS5ï¼‰
CREATE VIRTUAL TABLE flow_fts USING fts5(
    id,
    content,
    request,
    thinking,
    content='flow_index'
);
```

---

## äº”ã€æŸ¥è¯¢ä¸è¿‡æ»¤

### 5.1 è¿‡æ»¤å™¨è®¾è®¡

```rust
/// Flow è¿‡æ»¤å™¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowFilter {
    /// æ—¶é—´èŒƒå›´
    pub time_range: Option<TimeRange>,
    
    /// Provider è¿‡æ»¤
    pub providers: Option<Vec<ProviderType>>,
    
    /// æ¨¡å‹è¿‡æ»¤ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
    pub models: Option<Vec<String>>,
    
    /// çŠ¶æ€è¿‡æ»¤
    pub states: Option<Vec<FlowState>>,
    
    /// æ˜¯å¦æœ‰é”™è¯¯
    pub has_error: Option<bool>,
    
    /// æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    pub has_tool_calls: Option<bool>,
    
    /// æ˜¯å¦æœ‰æ€ç»´é“¾
    pub has_thinking: Option<bool>,
    
    /// æ˜¯å¦æµå¼
    pub is_streaming: Option<bool>,
    
    /// å†…å®¹æœç´¢ï¼ˆå…¨æ–‡ï¼‰
    pub content_search: Option<String>,
    
    /// è¯·æ±‚å†…å®¹æœç´¢
    pub request_search: Option<String>,
    
    /// Token èŒƒå›´
    pub token_range: Option<TokenRange>,
    
    /// å»¶è¿ŸèŒƒå›´
    pub latency_range: Option<LatencyRange>,
    
    /// æ ‡ç­¾è¿‡æ»¤
    pub tags: Option<Vec<String>>,
    
    /// åªæ˜¾ç¤ºæ”¶è—
    pub starred_only: bool,
    
    /// å‡­è¯ ID
    pub credential_id: Option<String>,
}

/// æ’åºé€‰é¡¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FlowSortBy {
    /// åˆ›å»ºæ—¶é—´ï¼ˆé»˜è®¤ï¼‰
    CreatedAt,
    /// è€—æ—¶
    Duration,
    /// Token æ•°
    TotalTokens,
    /// å†…å®¹é•¿åº¦
    ContentLength,
    /// æ¨¡å‹
    Model,
}
```

### 5.2 æŸ¥è¯¢ API

```rust
/// Flow æŸ¥è¯¢æœåŠ¡
pub struct FlowQueryService {
    memory_store: Arc<FlowMemoryStore>,
    file_store: Arc<FlowFileStore>,
}

impl FlowQueryService {
    /// æŸ¥è¯¢ flows
    pub async fn query(&self, 
        filter: FlowFilter, 
        sort_by: FlowSortBy,
        sort_desc: bool,
        page: usize,
        page_size: usize,
    ) -> Result<FlowQueryResult, Error> {
        // ä¼˜å…ˆä»å†…å­˜æŸ¥è¯¢
        let mut flows = self.memory_store.query(&filter);
        
        // å¦‚æœéœ€è¦æ›´å¤šæ•°æ®ï¼Œä»æ–‡ä»¶æŸ¥è¯¢
        if flows.len() < page * page_size {
            let file_flows = self.file_store.query(&filter).await?;
            flows.extend(file_flows);
        }
        
        // æ’åº
        self.sort_flows(&mut flows, sort_by, sort_desc);
        
        // åˆ†é¡µ
        let total = flows.len();
        let start = page * page_size;
        let end = (start + page_size).min(total);
        let flows = flows[start..end].to_vec();
        
        Ok(FlowQueryResult {
            flows,
            total,
            page,
            page_size,
        })
    }
    
    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self, filter: &FlowFilter) -> FlowStats {
        // è®¡ç®—èšåˆç»Ÿè®¡
    }
    
    /// å…¨æ–‡æœç´¢
    pub async fn search(&self, query: &str, limit: usize) -> Vec<FlowSearchResult> {
        // ä½¿ç”¨ FTS æœç´¢
    }
}
```

---

## å…­ã€å¯¼å‡ºåŠŸèƒ½

### 6.1 æ”¯æŒçš„å¯¼å‡ºæ ¼å¼

```rust
/// å¯¼å‡ºæ ¼å¼
pub enum ExportFormat {
    /// HAR (HTTP Archive) æ ¼å¼
    HAR,
    /// JSON æ ¼å¼
    JSON,
    /// JSONL (æ¯è¡Œä¸€ä¸ª JSON)
    JSONL,
    /// Markdown æ ¼å¼ï¼ˆç”¨äºæ–‡æ¡£ï¼‰
    Markdown,
    /// CSV æ ¼å¼ï¼ˆä»…å…ƒæ•°æ®ï¼‰
    CSV,
    /// OpenAI JSONLï¼ˆç”¨äº fine-tuningï¼‰
    OpenAIFineTune,
    /// Anthropic JSONLï¼ˆç”¨äº fine-tuningï¼‰
    AnthropicFineTune,
}

/// å¯¼å‡ºé€‰é¡¹
pub struct ExportOptions {
    /// å¯¼å‡ºæ ¼å¼
    pub format: ExportFormat,
    /// è¿‡æ»¤å™¨
    pub filter: FlowFilter,
    /// æ˜¯å¦åŒ…å«åŸå§‹æ•°æ®
    pub include_raw: bool,
    /// æ˜¯å¦åŒ…å«æµå¼ chunks
    pub include_stream_chunks: bool,
    /// æ˜¯å¦è„±æ•
    pub redact_sensitive: bool,
    /// è„±æ•è§„åˆ™
    pub redaction_rules: Vec<RedactionRule>,
    /// æ˜¯å¦å‹ç¼©
    pub compress: bool,
}
```

### 6.2 HAR å¯¼å‡º

```rust
impl FlowExporter {
    /// å¯¼å‡ºä¸º HAR æ ¼å¼
    pub fn export_har(&self, flows: &[LLMFlow]) -> HarArchive {
        HarArchive {
            log: HarLog {
                version: "1.2".to_string(),
                creator: HarCreator {
                    name: "ProxyCast".to_string(),
                    version: env!("CARGO_PKG_VERSION").to_string(),
                },
                entries: flows.iter().map(|f| self.flow_to_har_entry(f)).collect(),
                // LLM ç‰¹å®šæ‰©å±•
                _llm_metadata: Some(LLMHarMetadata {
                    total_tokens: flows.iter().map(|f| f.response.as_ref().map(|r| r.usage.total_tokens).unwrap_or(0) as u64).sum(),
                    models_used: flows.iter().map(|f| f.request.model.clone()).collect::<HashSet<_>>().into_iter().collect(),
                    providers_used: flows.iter().map(|f| f.metadata.provider.to_string()).collect::<HashSet<_>>().into_iter().collect(),
                }),
            },
        }
    }
    
    fn flow_to_har_entry(&self, flow: &LLMFlow) -> HarEntry {
        HarEntry {
            started_date_time: flow.timestamps.created.to_rfc3339(),
            time: flow.timestamps.duration_ms as f64,
            request: HarRequest {
                method: flow.request.method.clone(),
                url: format!("https://api.provider.com{}", flow.request.path),
                http_version: "HTTP/1.1".to_string(),
                headers: flow.request.headers.iter()
                    .map(|(k, v)| HarHeader { name: k.clone(), value: v.clone() })
                    .collect(),
                post_data: Some(HarPostData {
                    mime_type: "application/json".to_string(),
                    text: serde_json::to_string(&flow.request.body).unwrap(),
                }),
                // ...
            },
            response: flow.response.as_ref().map(|r| HarResponse {
                status: r.status_code as i32,
                status_text: r.status_text.clone(),
                headers: r.headers.iter()
                    .map(|(k, v)| HarHeader { name: k.clone(), value: v.clone() })
                    .collect(),
                content: HarContent {
                    size: r.size_bytes as i64,
                    mime_type: "application/json".to_string(),
                    text: Some(serde_json::to_string(&r.body).unwrap()),
                },
                // ...
            }),
            // LLM ç‰¹å®šæ‰©å±•
            _llm: Some(LLMHarExtension {
                provider: flow.metadata.provider.to_string(),
                model: flow.request.model.clone(),
                input_tokens: flow.response.as_ref().map(|r| r.usage.input_tokens),
                output_tokens: flow.response.as_ref().map(|r| r.usage.output_tokens),
                has_tool_calls: flow.response.as_ref().map(|r| !r.tool_calls.is_empty()).unwrap_or(false),
                has_thinking: flow.response.as_ref().and_then(|r| r.thinking.as_ref()).is_some(),
            }),
        }
    }
}
```

### 6.3 Markdown å¯¼å‡ºï¼ˆç”¨äºæ–‡æ¡£å’Œåˆ†äº«ï¼‰

```rust
impl FlowExporter {
    /// å¯¼å‡ºä¸º Markdownï¼ˆç”¨äºå¤åˆ¶åˆ†äº«ï¼‰
    pub fn export_markdown(&self, flow: &LLMFlow) -> String {
        let mut md = String::new();
        
        // æ ‡é¢˜
        writeln!(md, "# LLM Request - {}", flow.id).unwrap();
        writeln!(md, "").unwrap();
        
        // å…ƒä¿¡æ¯
        writeln!(md, "## Metadata").unwrap();
        writeln!(md, "- **Provider**: {}", flow.metadata.provider).unwrap();
        writeln!(md, "- **Model**: {}", flow.request.model).unwrap();
        writeln!(md, "- **Time**: {}", flow.timestamps.created).unwrap();
        writeln!(md, "- **Duration**: {}ms", flow.timestamps.duration_ms).unwrap();
        writeln!(md, "").unwrap();
        
        // è¯·æ±‚
        writeln!(md, "## Request").unwrap();
        if let Some(system) = &flow.request.system_prompt {
            writeln!(md, "### System Prompt").unwrap();
            writeln!(md, "```").unwrap();
            writeln!(md, "{}", system).unwrap();
            writeln!(md, "```").unwrap();
        }
        
        writeln!(md, "### Messages").unwrap();
        for msg in &flow.request.messages {
            writeln!(md, "**{}**:", msg.role).unwrap();
            writeln!(md, "{}", msg.content.to_string()).unwrap();
            writeln!(md, "").unwrap();
        }
        
        // å“åº”
        if let Some(resp) = &flow.response {
            writeln!(md, "## Response").unwrap();
            
            if let Some(thinking) = &resp.thinking {
                writeln!(md, "### Thinking").unwrap();
                writeln!(md, "<details><summary>Click to expand</summary>").unwrap();
                writeln!(md, "").unwrap();
                writeln!(md, "{}", thinking.text).unwrap();
                writeln!(md, "</details>").unwrap();
                writeln!(md, "").unwrap();
            }
            
            writeln!(md, "### Content").unwrap();
            writeln!(md, "{}", resp.content).unwrap();
            
            if !resp.tool_calls.is_empty() {
                writeln!(md, "### Tool Calls").unwrap();
                for tc in &resp.tool_calls {
                    writeln!(md, "- **{}**: `{}`", tc.function.name, tc.function.arguments).unwrap();
                }
            }
            
            writeln!(md, "### Usage").unwrap();
            writeln!(md, "- Input: {} tokens", resp.usage.input_tokens).unwrap();
            writeln!(md, "- Output: {} tokens", resp.usage.output_tokens).unwrap();
        }
        
        md
    }
}
```

---

## ä¸ƒã€å‰ç«¯ç•Œé¢è®¾è®¡

### 7.1 æµé‡åˆ—è¡¨è§†å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Search...  â”‚ Provider â–¾ â”‚ Model â–¾ â”‚ Status â–¾ â”‚ Time Range â–¾ â”‚ âš™ï¸ Export â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â­ 14:32:05 â”‚ claude-sonnet-4-5 â”‚ Kiro â”‚ âœ… 2.3s â”‚ 1.2kâ†’3.4k â”‚ ğŸ”§ tool â”‚ â”‚
â”‚ â”‚    "è¯·å¸®æˆ‘åˆ†æè¿™æ®µä»£ç çš„æ€§èƒ½é—®é¢˜..."                                    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚    14:31:42 â”‚ gemini-2.5-flash â”‚ Gemini â”‚ âœ… 0.8s â”‚ 500â†’1.2k â”‚         â”‚ â”‚
â”‚ â”‚    "Write a Python function to..."                                      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚    14:31:15 â”‚ claude-sonnet-4-5 â”‚ Kiro â”‚ âŒ 5.2s â”‚ Error: Rate limit   â”‚ â”‚
â”‚ â”‚    "Explain the difference between..."                                  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 æµé‡è¯¦æƒ…è§†å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Back â”‚ Request abc123 â”‚ â­ Star â”‚ ğŸ“‹ Copy â”‚ ğŸ“¤ Export â”‚ ğŸ”„ Replay        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Provider: Kiro          Model: claude-sonnet-4-5                      â”‚  â”‚
â”‚ â”‚ Duration: 2.3s          TTFB: 1.2s                                    â”‚  â”‚
â”‚ â”‚ Tokens: 1,234 â†’ 3,456   Cost: $0.045                                  â”‚  â”‚
â”‚ â”‚ Credential: work-account-1                                             â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Request â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ [Headers] [Body] [Messages] [Tools]                                   â”‚  â”‚
â”‚ â”‚                                                                       â”‚  â”‚
â”‚ â”‚ System: You are a helpful assistant...                                â”‚  â”‚
â”‚ â”‚                                                                       â”‚  â”‚
â”‚ â”‚ User: è¯·å¸®æˆ‘åˆ†æè¿™æ®µä»£ç çš„æ€§èƒ½é—®é¢˜ï¼š                                    â”‚  â”‚
â”‚ â”‚ ```python                                                             â”‚  â”‚
â”‚ â”‚ def slow_function():                                                  â”‚  â”‚
â”‚ â”‚     for i in range(10000):                                            â”‚  â”‚
â”‚ â”‚         result = expensive_operation(i)                               â”‚  â”‚
â”‚ â”‚ ```                                                                   â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ [Content] [Thinking] [Tool Calls] [Raw] [Stream]                      â”‚  â”‚
â”‚ â”‚                                                                       â”‚  â”‚
â”‚ â”‚ è¿™æ®µä»£ç å­˜åœ¨å‡ ä¸ªæ€§èƒ½é—®é¢˜ï¼š                                              â”‚  â”‚
â”‚ â”‚                                                                       â”‚  â”‚
â”‚ â”‚ 1. **å¾ªç¯ä¸­çš„é‡å¤è®¡ç®—**ï¼š`expensive_operation` è¢«è°ƒç”¨ 10000 æ¬¡...      â”‚  â”‚
â”‚ â”‚ 2. **ç¼ºå°‘ç¼“å­˜**ï¼šå¦‚æœæ“ä½œç»“æœå¯ä»¥é‡ç”¨...                                â”‚  â”‚
â”‚ â”‚                                                                       â”‚  â”‚
â”‚ â”‚ [Show more...]                                                        â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Timeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Request â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.1s     â”‚  â”‚
â”‚ â”‚ TTFB    â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 1.2s     â”‚  â”‚
â”‚ â”‚ Stream  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 1.0s     â”‚  â”‚
â”‚ â”‚ Total   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2.3s     â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 ç»Ÿè®¡ä»ªè¡¨æ¿

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ“Š Flow Statistics                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€ Token Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Total Requests    â”‚ 1,234           â”‚ â”‚                               â”‚  â”‚
â”‚ â”‚ Success Rate      â”‚ 98.2%           â”‚ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Input: 1.2M       â”‚  â”‚
â”‚ â”‚ Avg Latency       â”‚ 1.8s            â”‚ â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Output: 2.1Mâ”‚  â”‚
â”‚ â”‚ Total Tokens      â”‚ 3.3M            â”‚ â”‚                               â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Requests by Provider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Kiro     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 68%        â”‚â”‚
â”‚ â”‚ Gemini   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 22%        â”‚â”‚
â”‚ â”‚ OpenAI   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 10%        â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€ Latency Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€ Requests Timeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚     â–ƒâ–…â–ˆâ–‡â–…â–ƒâ–‚â–                       â”‚ â”‚ â–‚â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–‚â–â–‚â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–‚          â”‚  â”‚
â”‚ â”‚ 0s  1s  2s  3s  4s  5s+            â”‚ â”‚ 00:00    06:00    12:00   18:00â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å…«ã€API è®¾è®¡

### 8.1 Tauri Commands

```rust
// æŸ¥è¯¢ flows
#[tauri::command]
async fn query_flows(
    filter: FlowFilter,
    sort_by: Option<FlowSortBy>,
    sort_desc: Option<bool>,
    page: Option<usize>,
    page_size: Option<usize>,
    state: State<'_, FlowMonitorState>,
) -> Result<FlowQueryResult, String>;

// è·å–å•ä¸ª flow è¯¦æƒ…
#[tauri::command]
async fn get_flow_detail(
    id: String,
    state: State<'_, FlowMonitorState>,
) -> Result<LLMFlow, String>;

// æœç´¢ flows
#[tauri::command]
async fn search_flows(
    query: String,
    limit: Option<usize>,
    state: State<'_, FlowMonitorState>,
) -> Result<Vec<FlowSearchResult>, String>;

// è·å–ç»Ÿè®¡ä¿¡æ¯
#[tauri::command]
async fn get_flow_stats(
    filter: Option<FlowFilter>,
    state: State<'_, FlowMonitorState>,
) -> Result<FlowStats, String>;

// å¯¼å‡º flows
#[tauri::command]
async fn export_flows(
    options: ExportOptions,
    path: String,
    state: State<'_, FlowMonitorState>,
) -> Result<ExportResult, String>;

// æ›´æ–° flow æ ‡æ³¨
#[tauri::command]
async fn update_flow_annotations(
    id: String,
    annotations: FlowAnnotations,
    state: State<'_, FlowMonitorState>,
) -> Result<(), String>;

// é‡æ”¾è¯·æ±‚
#[tauri::command]
async fn replay_flow(
    id: String,
    modifications: Option<FlowModifications>,
    state: State<'_, FlowMonitorState>,
) -> Result<LLMFlow, String>;

// æ¸…ç†æ—§æ•°æ®
#[tauri::command]
async fn cleanup_flows(
    before: DateTime<Utc>,
    state: State<'_, FlowMonitorState>,
) -> Result<CleanupResult, String>;
```

### 8.2 WebSocket å®æ—¶æ¨é€

```rust
/// å®æ—¶ Flow äº‹ä»¶
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type")]
pub enum FlowEvent {
    /// æ–° flow å¼€å§‹
    FlowStarted { flow: FlowSummary },
    /// flow æ›´æ–°ï¼ˆæ”¶åˆ°å“åº”æ•°æ®ï¼‰
    FlowUpdated { id: String, update: FlowUpdate },
    /// flow å®Œæˆ
    FlowCompleted { id: String, summary: FlowSummary },
    /// flow å¤±è´¥
    FlowFailed { id: String, error: FlowError },
    /// ç»Ÿè®¡æ›´æ–°
    StatsUpdated { stats: FlowStats },
}

/// Flow æ‘˜è¦ï¼ˆç”¨äºåˆ—è¡¨æ˜¾ç¤ºï¼‰
#[derive(Debug, Clone, Serialize)]
pub struct FlowSummary {
    pub id: String,
    pub provider: String,
    pub model: String,
    pub state: FlowState,
    pub duration_ms: Option<u64>,
    pub input_tokens: Option<u32>,
    pub output_tokens: Option<u32>,
    pub content_preview: String,
    pub has_error: bool,
    pub has_tool_calls: bool,
    pub created_at: DateTime<Utc>,
}
```

---

## ä¹ã€æ€§èƒ½ä¸éšç§

### 9.1 æ€§èƒ½ä¼˜åŒ–

```rust
/// Flow ç›‘æ§é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowMonitorConfig {
    /// æ˜¯å¦å¯ç”¨ç›‘æ§
    pub enabled: bool,
    
    /// å†…å­˜ä¸­æœ€å¤§ flow æ•°é‡
    pub max_memory_flows: usize,
    
    /// æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
    pub persist_to_file: bool,
    
    /// æ–‡ä»¶ä¿ç•™å¤©æ•°
    pub retention_days: u32,
    
    /// æ˜¯å¦ä¿å­˜åŸå§‹ stream chunks
    pub save_stream_chunks: bool,
    
    /// è¯·æ±‚ä½“å¤§å°é™åˆ¶ï¼ˆè¶…è¿‡åˆ™æˆªæ–­ï¼‰
    pub max_request_body_size: usize,
    
    /// å“åº”ä½“å¤§å°é™åˆ¶
    pub max_response_body_size: usize,
    
    /// æ˜¯å¦ä¿å­˜å›¾ç‰‡å†…å®¹ï¼ˆbase64ï¼‰
    pub save_image_content: bool,
    
    /// å›¾ç‰‡ç¼©ç•¥å›¾å¤§å°
    pub thumbnail_size: (u32, u32),
    
    /// é‡‡æ ·ç‡ï¼ˆ0.0-1.0ï¼Œç”¨äºé«˜æµé‡åœºæ™¯ï¼‰
    pub sampling_rate: f32,
    
    /// æ’é™¤çš„æ¨¡å‹ï¼ˆä¸è®°å½•ï¼‰
    pub excluded_models: Vec<String>,
    
    /// æ’é™¤çš„è·¯å¾„
    pub excluded_paths: Vec<String>,
}

impl Default for FlowMonitorConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            max_memory_flows: 1000,
            persist_to_file: true,
            retention_days: 7,
            save_stream_chunks: false, // é»˜è®¤ä¸ä¿å­˜åŸå§‹ chunks
            max_request_body_size: 1024 * 1024, // 1MB
            max_response_body_size: 10 * 1024 * 1024, // 10MB
            save_image_content: false, // é»˜è®¤ä¸ä¿å­˜å›¾ç‰‡
            thumbnail_size: (100, 100),
            sampling_rate: 1.0,
            excluded_models: vec![],
            excluded_paths: vec!["/health".to_string()],
        }
    }
}
```

### 9.2 éšç§ä¿æŠ¤

```rust
/// è„±æ•è§„åˆ™
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RedactionRule {
    /// è§„åˆ™åç§°
    pub name: String,
    /// åŒ¹é…æ¨¡å¼ï¼ˆæ­£åˆ™ï¼‰
    pub pattern: String,
    /// æ›¿æ¢å†…å®¹
    pub replacement: String,
    /// åº”ç”¨ä½ç½®
    pub apply_to: Vec<RedactionTarget>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RedactionTarget {
    /// è¯·æ±‚å¤´
    RequestHeaders,
    /// è¯·æ±‚ä½“
    RequestBody,
    /// å“åº”å¤´
    ResponseHeaders,
    /// å“åº”ä½“
    ResponseBody,
    /// æ‰€æœ‰ä½ç½®
    All,
}

impl Default for Vec<RedactionRule> {
    fn default() -> Self {
        vec![
            // API Key è„±æ•
            RedactionRule {
                name: "api_key".to_string(),
                pattern: r"(sk-[a-zA-Z0-9]{20,}|api[_-]?key[=:]\s*['\"]?)[a-zA-Z0-9\-_]+".to_string(),
                replacement: "$1***REDACTED***".to_string(),
                apply_to: vec![RedactionTarget::All],
            },
            // Email è„±æ•
            RedactionRule {
                name: "email".to_string(),
                pattern: r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}".to_string(),
                replacement: "***@***.***".to_string(),
                apply_to: vec![RedactionTarget::RequestBody, RedactionTarget::ResponseBody],
            },
            // æ‰‹æœºå·è„±æ•
            RedactionRule {
                name: "phone".to_string(),
                pattern: r"\b1[3-9]\d{9}\b".to_string(),
                replacement: "1**********".to_string(),
                apply_to: vec![RedactionTarget::RequestBody, RedactionTarget::ResponseBody],
            },
        ]
    }
}
```

---

## åã€å®ç°è·¯çº¿å›¾

### Phase 1: åŸºç¡€è®¾æ–½ï¼ˆ1-2 å‘¨ï¼‰

- [ ] å®šä¹‰å®Œæ•´çš„æ•°æ®æ¨¡å‹ï¼ˆLLMFlow, LLMRequest, LLMResponseï¼‰
- [ ] å®ç°å†…å­˜å­˜å‚¨ FlowMemoryStore
- [ ] å®ç° SSE æµé‡å»ºå™¨ StreamRebuilder
- [ ] åœ¨ç°æœ‰ API handlers ä¸­é›†æˆ flow æ•è·

### Phase 2: æŒä¹…åŒ–ä¸æŸ¥è¯¢ï¼ˆ1-2 å‘¨ï¼‰

- [ ] å®ç°æ–‡ä»¶å­˜å‚¨ FlowFileStore
- [ ] å®ç° SQLite ç´¢å¼•
- [ ] å®ç°æŸ¥è¯¢è¿‡æ»¤å™¨
- [ ] æ·»åŠ å…¨æ–‡æœç´¢æ”¯æŒ

### Phase 3: å‰ç«¯ç•Œé¢ï¼ˆ2-3 å‘¨ï¼‰

- [ ] å®ç° Flow åˆ—è¡¨é¡µé¢
- [ ] å®ç° Flow è¯¦æƒ…é¡µé¢
- [ ] å®ç°ç»Ÿè®¡ä»ªè¡¨æ¿
- [ ] å®ç°å®æ—¶æ›´æ–°ï¼ˆWebSocketï¼‰

### Phase 4: å¯¼å‡ºä¸é«˜çº§åŠŸèƒ½ï¼ˆ1-2 å‘¨ï¼‰

- [ ] å®ç° HAR å¯¼å‡º
- [ ] å®ç° Markdown å¯¼å‡º
- [ ] å®ç°è¯·æ±‚é‡æ”¾
- [ ] å®ç°éšç§è„±æ•

### Phase 5: ä¼˜åŒ–ä¸æ–‡æ¡£ï¼ˆ1 å‘¨ï¼‰

- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] ç¼–å†™ç”¨æˆ·æ–‡æ¡£
- [ ] æ·»åŠ æµ‹è¯•ç”¨ä¾‹
- [ ] å‘å¸ƒ v1.0

---

## åä¸€ã€é™„å½•

### A. ä¸ç°æœ‰ç³»ç»Ÿçš„é›†æˆç‚¹

1. **server/handlers/api.rs**: åœ¨ `chat_completions` å’Œ `anthropic_messages` å‡½æ•°ä¸­æ·»åŠ  flow æ•è·
2. **server_utils.rs**: å¤ç”¨ `parse_cw_response` ç”¨äºæµå¼å“åº”è§£æ
3. **services/provider_pool_service.rs**: è·å–å‡­è¯ä¿¡æ¯ç”¨äº metadata
4. **models/log_model.rs**: å°† RequestLog ä¸ LLMFlow å…³è”

### B. å‚è€ƒå®ç°

- [mitmproxy](https://github.com/mitmproxy/mitmproxy) - HTTP æµé‡æ•è·çš„é»„é‡‘æ ‡å‡†
- [Charles Proxy](https://www.charlesproxy.com/) - å•†ä¸šä»£ç†è°ƒè¯•å·¥å…·
- [Fiddler](https://www.telerik.com/fiddler) - .NET å¹³å°ä»£ç†è°ƒè¯•å·¥å…·
- [LangSmith](https://smith.langchain.com/) - LangChain å®˜æ–¹çš„ LLM å¯è§‚æµ‹æ€§å¹³å°

### C. æ•°æ®å¤§å°ä¼°ç®—

| åœºæ™¯ | è¯·æ±‚æ•°/å¤© | å¹³å‡å¤§å° | æ—¥å­˜å‚¨é‡ | æœˆå­˜å‚¨é‡ |
|------|----------|---------|---------|---------|
| ä¸ªäººå¼€å‘ | 100 | 10KB | 1MB | 30MB |
| å›¢é˜Ÿå¼€å‘ | 1,000 | 15KB | 15MB | 450MB |
| ç”Ÿäº§ç¯å¢ƒ | 10,000 | 20KB | 200MB | 6GB |

### D. å®‰å…¨è€ƒè™‘

1. **æœ¬åœ°å­˜å‚¨**ï¼šæ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨æœ¬åœ°ï¼Œä¸ä¸Šä¼ åˆ°ä»»ä½•æœåŠ¡å™¨
2. **è®¿é—®æ§åˆ¶**ï¼šé€šè¿‡ API Key éªŒè¯è®¿é—®
3. **æ•°æ®åŠ å¯†**ï¼šæ•æ„Ÿæ•°æ®å¯é€‰åŠ å¯†å­˜å‚¨
4. **å®¡è®¡æ—¥å¿—**ï¼šè®°å½•æ‰€æœ‰å¯¼å‡ºå’Œè®¿é—®æ“ä½œ

---

## åäºŒã€å¼€æ”¾é—®é¢˜

1. **å›¾ç‰‡å¤„ç†ç­–ç•¥**ï¼šæ˜¯å¦ä¿å­˜å®Œæ•´çš„ base64 å›¾ç‰‡å†…å®¹ï¼Ÿè¿˜æ˜¯åªä¿å­˜ç¼©ç•¥å›¾ï¼Ÿ
2. **éŸ³é¢‘å¤„ç†**ï¼šå¦‚ä½•å¤„ç†éŸ³é¢‘å†…å®¹ï¼Ÿ
3. **å¤šç§Ÿæˆ·æ”¯æŒ**ï¼šæ˜¯å¦éœ€è¦æ”¯æŒå¤šä¸ª workspace éš”ç¦»æ•°æ®ï¼Ÿ
4. **äº‘åŒæ­¥**ï¼šæ˜¯å¦éœ€è¦æ”¯æŒè·¨è®¾å¤‡åŒæ­¥ flow æ•°æ®ï¼Ÿ
5. **å¯¹æ¯”åŠŸèƒ½**ï¼šæ˜¯å¦éœ€è¦æ”¯æŒä¸¤ä¸ª flow çš„å¯¹æ¯”åŠŸèƒ½ï¼Ÿ
6. **å›å½’æµ‹è¯•**ï¼šæ˜¯å¦éœ€è¦å°†ä¿å­˜çš„ flow ä½œä¸ºå›å½’æµ‹è¯•ç”¨ä¾‹ï¼Ÿ

---

*æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0*
*æœ€åæ›´æ–°ï¼š2024-01*
*ä½œè€…ï¼šProxyCast Team*
